{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验1 线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 一、实验目的\n",
    "\n",
    "掌握线性回归、对数几率回归和线性判别分析的原理与应用，熟悉Scikit-learn中算法的使用。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.线性回归 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）随机线性数据的最小二乘回归  \n",
    "  参考教材3.2节，线性模型$f\\left(\\boldsymbol x\\right) = \\boldsymbol w^T + b$ 参数的最优解为\n",
    " \n",
    "  $$\\hat{\\boldsymbol w}^* = \\left(X^TX\\right)^{-1}X^T\\boldsymbol y$$ \n",
    "      \n",
    "利用随机生成的线性数据来学习模型并进行验证。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3a0847372cc7433c8917bccd718e40ed2bed08f278e44a30b9372212fef41069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1）生成数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机线性数据的最小二乘回归\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "X= 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.rand(100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2）模型学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = np.c_[np.ones((100,1)), X]\n",
    "w_best = np.linalg.inv(Xb.T.dot(Xb)).dot(Xb.T).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3） 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.array([[0],[2]])\n",
    "Xnewb = np.c_[np.ones((2,1)), Xnew]\n",
    "y_predict = Xnewb.dot(w_best)\n",
    "\n",
    "plt.plot(Xnew,y_predict,\"r-\")\n",
    "plt.plot(X,y,\"b.\")\n",
    "#plt.axis([0,2,0,15])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）使用Scikit-Learn 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "阅读Scikit-learn手册中最小二乘线性回归的用法（https://scikit-learn.org/0.20/modules/linear_model.html#ordinary-least-squares）。\n",
    "\n",
    "参考代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X,y)\n",
    "#......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用LinearRegression类来实现（1）中回归任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.55355347]\n",
      " [10.45396195]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XuclGX5x/HPtbssiJUpkphKQP08Rmquh6m0VTRPmRmWhwwFBUtRQUUhPCWekwRTDDRE0h+eiLQsAVc3eP0YD4snIEQTPEAq26aSKLuwe//+uGdgdpnzPDM7M/t9v1772tl5nnnm9mG89t7rPlzmnENEREpfRWc3QEREgqGALiJSJhTQRUTKhAK6iEiZUEAXESkTCugiImVCAV1EpEwooIuIlImUAd3MppvZWjNbGvPcj81smZm1mVlNfpsoIiLpqErjnBnAHcDMmOeWAj8CpmbyZjvuuKPr169fJi8REenyFi9e/G/nXO9U56UM6M65BWbWr8NzywHMLKNG9evXj4aGhoxeIyLS1ZnZ2+mcpxy6iEiZyHtAN7MRZtZgZg2NjY35fjsRkS4r7wHdOTfNOVfjnKvp3TtlCkhERLKklIuISJlIZ9riLCAM7GFmq83sbDM7ycxWAyHgCTObm++GiohIcunMcjktwaE5AbdFRERyoJSLiEiWwmG48Ub/vRiks7BIREQ6CIdh0CBoaYHqaqirg1Coc9ukHrqISBbq630wb2313+vrO7tFCugiIlmprfU988pK/722Nv55hUzLKOUiIpKFUMinWerrtwTzG2/0j6Opl0KnZRTQRUSyFAr5r0SBO15aJp8BXSkXEZEcJcqnp5uWCYp66CIiOYoG7mgPPRq4O6Zl8j0LRgFdRCRHyQJ3NC1TCAroIiIBKGTgTkQ5dBGRfGprg4cfhk2b8v5WCugiIvny3HNwyCFwyikwe3be304BXUQkaO+/D0OH+mC+ejX84Q/wk5/k/W0V0EWky8nb6s2WFpg4EXbfHR54AC6/HFasgDPOgAxrMGdDg6Ii0qXkbfXm3Llw0UU+gB93HNx2mw/sBaQeuoh0KYFvqvXmm3DiiXDMMf6if/kLPPFEwYM5KKCLSBcT2OrNTz6B8eNh7719N/+mm2DpUjj++ABbmxmlXESkS8l59aZz8OCDMGYMrFnj8+M33wxf/nIeWpsZBXQR6XKyXgT08stw4YWwcCF885vw0EPw7W8H3r5sKeUiIiWn4KXfmprgvPPggANg+XKYNg2efz5pMO+M8nTqoYtISSnoHuObNvngfcUVsG4djBwJ11wD229fPG2MoR66iJSUgpV++/vffY/8/PMJ9z+dG0euJnzq5JTBvKBt7CBlQDez6Wa21syWxjy3g5nNN7M3It9T/xeKiAQg73uMv/sunHqqv/BHHxG+ro5By3/LlXf0YdCg9FIohd4HPSqdHvoM4JgOz40F6pxz/wPURX4WEcm76CyVCRPST2Wklc/esAGuuw722AMeewyuvhqWL6e+4ghaWozWVn/KzJn5aWMgnHMpv4B+wNKYn1cAO0ce7wysSOc6BxxwgBMRKaRFi5zbZhvnKiv990WLOpzQ1ubcnDnO9e/vHDg3eLBzq1a1e311tT8EznXvHucakfNuuCH+sVwBDS6NGJttDn0n59x7kcfvAzslOtHMRphZg5k1NDY2Zvl2IiLZSZrPXr7cr/A86STYZht46il49FHo12/zKaEQDBu2ZSuWTZu2zolHB0GvvJK00zL5kPOgaOS3h0tyfJpzrsY5V9O7d+9c305EJCNx89kffwyXXALf+Ibf4nbyZD/HfNCguNcYMgR69EicE++sQdCOsp22+IGZ7eyce8/MdgbWBtkoEZGgtFsZelgbodfugx+OhcZGOOccuP56SNHZTLW6NFFN0ULLNqA/DpwJ3BT5/lhgLRIRCVgoBKGK5+CCC+CFF/wTf/2rn5aYyTUSDG4Wuhh0IikDupnNAmqBHc1sNXA1PpA/bGZnA28D+d+5XUQkG++/D+PGwYwZ0KePn6by059CRbDLcIqhpmjKgO6cOy3BofjJJhGRYtDSAr/9LfzqV36+4WWX+RWfn/98Z7csb7T0X0TKT2yxiWOPhUmTctqfPBzu/HRKOhTQRaR8rFwJF19M+LEPqN/hHGp/HSJ0aW67IXbWvizZ0F4uIlL61q/36ZS99yY8dx2Dui3gyo8vYdBV3855TnixTElMhwK6iBRcYFvLRotN7LGHn3548snUj5pDS1s3WlstkADcWfuyZEMpFxEpqMBSGK+84qchLlwI+++/udhEbRiqJwc3J7xYpiSmQwFdRAoqXgojoyDZ1OTX2E+d6reynToVzj7bd6HJTwAuhimJ6VBAF5GCynpVZWurD97RYhPnn++nJMbZn7xUAnDQFNBFpKCy6kEvWOBreb7yChx+uN97ZeDAPLe09Cigi0jBpd2DfvddvyDowQehb1945BEYPHjL1ofSjgK6iBSfDRtg4kS44QZoa/PFJi67DHr27OyWFTUFdBEpHs7B44/D6NGwapXvjd96a7v9ySUxzUMXkYKLOw/9tdd8sYkf/tAXm5g/f6tiE5KceugiUlBbzUN/7BNCT14Nt98O227r91057zzo1q2zm1pyFNBFpKDazUNvbqP+pMmEPr3NzyW//nr40pc6u4klSwFdRAqqthaqq1ppaXVUt7VQ2+8tmPE81NR0dtNKngK6iBTOBx8Qunscdc3Lqf/cCdSO3p/QNVMDLzbRVSmgi0j+tbTAHXf4lZ2ffUbostGErrigrItNdAYFdBHJr3nzfLGJ114LpNiEJKa/c0QkP1au9FMQjz4aNm6EP/8ZnngiaTAPbFvdLko9dBHJSsKybOvX+6h8661QVeUfjx4N3bunvF6pVAYqVgroIpKxuMH3EOf3JB8zBlavhp/+FG6+GXbZJa1r5rytruSWcjGzi8xsqZktM7NRQTVKRIrbVsF31nu+q37aadC7ty86cf/9aQdzaF8ZqKoK3nlHqZdMZR3QzezrwHDgIGBf4Ptm9rWgGiYihZNp7npL8HVUWwu1d5wMy5b5/cpfeAG+852M2xDdVnf4cL+ly913+78CFNTTl0vKZS/gOefcpwBm9nfgR8AtQTRMRAojHPZbjEfTJ888kzrVETqolbrzH6P+zmXUbniS0MgD4Fd/iVtsIhOhkO/9t7Yq9ZKNXFIuS4FDzayXmfUEjgN263iSmY0wswYza2hsbMzh7UQkH2bOhOZm3ytubvY/J7VgARxwAKFbBzPu4KcJvfI7vw9LBsE82V8EpVSUudhk3UN3zi03s5uBecB64GWgNc5504BpADU1NS7b9xORThZbbGK33eDhh+HkkzMuNpFqNkspFWUuNjkNijrnfu+cO8A5dxjwIfB6MM0SkUIZMsQHVjP/fciQDids2OA3zdpzT5gzB666yi8S+vGPs6ocFG82S0ehEIwbp2CeqZymLZrZl5xza82sLz5/fkgwzRKRQonmrbfqETvnFwONHk145Zeo32cqtb86gtDgL2f1PtF56716ZVkkWlLKdR76bDPrBWwEznfOfRRAm0SkwLaq8fnaazBqFMydS/grpzKo+/20vFZJ9c+g7suZ95w7plkmTYKmJqVUgpZTQHfOHRpUQ0QkOwlXbKZ5vJ116+Daa2Hy5M3FJur/O5KWaypzmnXSMc3S1ORTKhIsrRQVKSEdg3OqAca0l9O3tfnpLWPHwtq17YpN1Iah+obcUiTRmStKs+SXArpIiYgXnFMtl09rOf3zz8MFF/jvhxzi8+YHHrj5cBCzTjRzpTAU0EVKRLzgnKrnm/T4Bx/4vMe990KfPnDffXDGGXGLTWyVYyfDVE6Ca0iwFNBFSkS84Jyq5xv3+MaN8Nvfbi42wZgxcMUV8IUvpN0W7YxYnBTQRUpEouCdqufb7vj8+XDhhX4WyzHH+Okme+yRcVu0M2JxUkAXKSFZpy1WroRLLoE//Qm++lWfJz/++KwWBoEGOYuVArpIOVu/Hm66CX7965TFJjLJiWuQszgpoIuUga2CsXN+r5VLL/XFJk4/HW65JeH+5Mly4okCvQY5i48CukgnynSmSKJrtAvGv3uD0O/P8bsi7rcfzJqVcn/yRDlxDX6WFgV0kTxLFLSDCpbtgvGGVurPupfQDsvgd7+Dc87x+9CmEM2JNzf7tHqvXnGurcHPoqeALpJHyYJ2UMGy9tBWqivaaGmFareR2sG9YNrrsMMOaV8jFPITXkaO9O0ZNQoGDtTgZ6nJaftcEUku2VaxgRRyWLiQ0MgDqNt4GBP6z6Bu5r8IPXpJRsE8qqnJ7wDQ1tb+F0xdHUyYoHRLKVAPXSSPkvVwc5opsnq1LzYxaxbsthuhhycSyqLYRDpt1eBn6TDnCldEqKamxjU0NBTs/USKQVADn/X1UBtqJrRoot84q7UVLr/cf/XsWTRtleCZ2WLnXE3K8xTQRYqbz8M7Wpod1a6ZOncEoZN2hokToX//zm6eFEC6AV0pF5EiV//IWlo+60UrlbTQjfphfyD0+691drOkCGlQVKRYrVsHl15K7e2DqaaZyoo2qreppPYcBXOJTz10kWLT1gZ/+IPPja9dS2jYMOpO2kD9qz2V25akFNBFiskLL/hiE889167YRAgIHZ/bpTXgWf4U0EWKwQcfwC9/CdOnw047JS02kQ0t4e8alEMX6UwbN8Jtt8Huu/s0y5gx8PrrMGRIYMEcki9wkvKR0yfGzEab2TIzW2pms8ysR1ANEyl78+fDvvvCxRf77vKSJX5HxAwqB6UrkFWpUvSyTrmY2S7AhcDezrnPzOxh4FRgRkBtEylL4UfXUH/109T+YwqhAc3w+OPw/e/ntMozFe1f3jXkmkOvArYxs41AT+BfuTdJpEytX0945AMMmnEGLZxGdbdTqft9G6HarYtN5IOW8Je/rFMuzrk1wK3AO8B7wMfOuXlBNUykbESLTey1F/UzVtFCd1qpoqWtG/XhwgRz6RqyDuhmtj1wItAf+DKwrZmdEee8EWbWYGYNjY2N2bdUpBOFw756Wzic4QtffRUOPxxOOQV69aJ2yilUb1OpXLbkRS4plyOBVc65RgAz+yPwLeD+2JOcc9OAaeD3csnh/UQ6RVZT/v7zH7jqKrjrLth++83FJkKVldTttyWXDf4XhfLaEoRcAvo7wCFm1hP4DBgEaOctKTsZFaJobYW774bx4+Gjj+AXv4Brr223P3k0l6254RK0XHLozwGPAi8CSyLXmhZQu0SKRtpT/hYuhJoaH8QHDoSXXoI77khYbEJzwyVoOc1ycc5dDVwdUFtE8i6b5e8pp/x1KDbBQw/Bj3+cchqiyrtJ0LT0X7qMXFIccaf8bdgAv/nNlmITV17pN9Tadtu0r6m54RIkBXTpMgKrYO8c/OUvMHo0vPkmnHRSu2ITmfwVoLnhEiQFdOkyAklxrFgBo0bBk0/CXnvBvHlw1FGbD2ugUzqTNueSLiOnCvbr1vmNs77+dVi0yG+o9cor7YI5aKBTOpd66NKlZJzi6FBsgqFD4YYb/Ba3EbEplkR/BWgvcikEBXSRGNOmwezZMHgwjNg/ptjEwQdvLjYRK16KpeNAp9IwUigK6CIR06bBuecCOObNA5jGiJ3eghkz4Gc/i7s/eWyKpbkZrrnGf40bF/+cnAZjRVJQDl0kYvYjbYAD/Pzx2f0u9cUmzjwzYbGJaIqlosJnZ556yvfGY/d80V7kUigK6FJWst5Ea/58Bi+9JvKD33Jo8Lg9UhabiA60HnnklqDecTA0p8FYkQwo5SJlI6tc9apVcMklMGcOIwYMgPMHM/uNbzB4sDFiRHrvGwr5NMvChYmnRGq+uRSCArqUjYxy1Z9+Cjfd5Eu+VVb6mSujRzOiRw/SjOPtaNWnFAMFdCkb0Vx1c7PfRqVXrzgnOQePPAKXXgrvvgunnw433wy77prz+6sXLp1NOXQpapnkxEMhmDTJd7jb2vyCznavW7IEjjjCF5vYYQdYsAAeeCCQYC5SDBTQpWhFc+JXXrn1zJFEmpp8yqWtzffU6+vxxSZGjoT99vMVhO66CxYvJlx1aHYDqCJFSikXKVrZzN/u1csHc4C2NsdH9S/DxKPgww/bFZvQYh8pR+qhS9HKZv52U1P7bcgnzvs6v6i+h/CMFe2KTWjPFSlH6qFL0cpm5kjtPo1UsT0bqQSMVqqY+v6J3HeuUfe1LddQcQkpRwroUtTSnjnS3Ay/+Q2h66/njoohnO9uZ1ObD+rObZ2yif1l0avXlh660i5SyhTQpbR1LDbxwx8yYuKlDPygipkzYfp0n1ZJtNgHlEuX8qGALqUrttjEnnvC3Lnwve8BEBrgA/OQIclTNto4S8qJAroUhYz2C1+3zm+MMmkS9Ozp63qOHAndum11aqqUjXLpUk6yDuhmtgfwUMxTA4CrnHOTcm6VdClpTyFsa4P77/fFJt5/H4YN26rYRKa0ZF/KSdYB3Tm3AtgPwMwqgTXAnIDaJV1IWmmPF16ACy+EZ5/1xSYeewwOOiiQ99eSfSkXQc1DHwS86Zx7O6DrSReSdL752rVwzjk+iK9a5YtNLFoUWDAXKSdB5dBPBWYFdC3pYuKmPTZuhDvv9PvSrl8PF1/s9wDYbrutXq96nSKeOedyu4BZNfAvYB/n3Adxjo8AvyNp3759D3j7bXXiJYWnnvLpleXL4eij/eDnnnvGPVVL+KUrMLPFzrmaVOcFkXI5FngxXjAHcM5Nc87VOOdqevfuHcDbSTHJukJQPKtWwY9+BEcd5RcKPfYY/O1vCYM5aAm/SKwgUi6noXRLlxRY7/jTT/2e5Lfc4uu4XX+9T7H06JHypZp2KLJFTgHdzLYFjgLODaY5UkpyXpTjHDz6qC8B9+67cNppPqh32J88WY5c0w5FtsgpoDvn1gPx6sJIGUg12Jisd5xyoHLJEp8nr6+Hfff1hSYOPTRuG1L9FaBphyKeVopKXOkG0ni946Sv/c9/4OqrYcoU+OIXfbGJ4cP9nMU46ut9Oj22YIWCt0h8CugSV7rplHi947ivPagV7rkHxo/fqthEMu0LViSoEyoigAK6JJDLYONWr93hVTjwLHjpJTjsMLj9dp9mSUNTkx8nbWvz35uasviPEekiFNAlrlwGGze/9vGPqV38G0I/v9YPdD74IPzkJ+1LCqVQWwvdu2sWi0g6cl5YlImamhrX0NBQsPeTTtLcDLfdBtddB5s2wZgxMHYsbLttVpfTSlDp6tJdWKQeugTHOXjiCb9HeaTYBBMnwoABOV1Ws1hE0qMi0RKMFSvg+OPhhBP8vuRz58KcOTkHcxFJn3rokpXNaZAD1xOa9yu/38o22yQtNiEi+aWALhnz88wdLc2O6rYK6lhIaOgZflOXHIpNiEhuFNAlY/X3r6blsz60UsUGqpl50p8ITVcgF+lsyqFL+iLFJmqn/IRKWgGHo4J7/7pTMLstikhOFNAltY0bYfJk2H13uO8+Qpd8i2FDwcwAY9MmbVsrUgwU0CW5p56C/fbzUxEPPthvqnXrrQwZ3p0ePRKUjRORTqEceonquNgm8MU3b73lt7X94x/91MPHHvNTEiOrPLVtrUjxUUAvQR13M5w0yXegAynD1rHYxHXX+cAep9iEFvyIFBcF9BITDvu6ydEtZVtaYPbszAtNxPboAeqfcdS6pwlNHZq02ISIFC8F9BIS7ZlHg3lFhe+RDx4MCxemv4HVtGlw/vn+GlVVYLSxqcVRTYi6r36X0N+H+10RRaSkKKCXkOg+49FgfuSRvrceCsHAgenls8Nhv5Bz0yb/88aWNvz0w0paKnpQP3QGocPiF5sQkeKmgF5COu4zHg3mkH4+u74eWlsdYICjglaqKmETFVRXV1B7RN6aLyJ5poBeQoKYWVK7w6t0d7vTTBWVBndc8T4Dj91Ns1VEyoD2Q+8q1qyByy+HBx4g3PsH1A+aQO0FAwl9K/1iEyLSObQfuviZLE9tovZf/0voD+f5xPkVVxAaO5ZQlsUmRKR45RTQzeyLwD3A1wEHDHPOaVePIhAOw6DaVp9v52TqDl1GaMa52p9cpIzl2kOfDDzpnDvZzKqBngG0qawFvaIz7orRRxt555HnaWk5mlaqaKmooP7YmwkplouUtawDupltBxwGnAXgnGsBWoJpVnnquMIzpxWdca436abPGHVJJS2btqeKQVRWAjg/e6U2oP8IESlauWzO1R9oBO41s5fM7B4z2yoxa2YjzKzBzBoaGxtzeLvSF51HHruiM7DrNbcxe8yztGyqoJUqNlV2Z9jwKiZMsJx/cYhIacgloFcB3wTucs7tD6wHxnY8yTk3zTlX45yr6d27dw5vV/qi88iD2qGwthaqq1qpZBPVbRsYvHOY6u4Wub4xZAiMG5feNgA33oj2NBcpcbnk0FcDq51zz0V+fpQ4AV22CHSHwrVrCU0fT13zMuq3PZ7aUfsRunYsA5+ryOj6QaeBRKTzZB3QnXPvm9m7ZraHc24FMAj4R3BNK08571C4cSNMmQJXXw3r1xO6+EJCV42E7bbL6vrx0kAK6CKlKddZLhcAD0RmuKwEhubeJEmorg4uvBD+8Q/43vf8vrl77ZXTJTtuJ6DBU5HSlVNAd869DKRcvdSVBTJNMbbYRP/+8Kc/wQ9+sLnYRC5UqEKkfGilaB7lnJ/+9FPCF/wvM+9rA45hyIgTCE0+NW6xiVyoUIVIeVBAz4Nor/ydd9rnp2fOTLMn7BzMnk145AMc/sEsmukOwPQZRv1ZCr4iEp8CeoaSpVDCYR+0773Xb5tSVUVkcY//Hvv80KEwZEic4Lx0qc+TP/MM9X0m0WLdwfnUysaNqQctA68tKiIlQwE9A8lSKNFjGzb4DnbU8OHQt6/vrd99t++tt7bC1Klw330x1/jwQz9zZcoUP2NlyhRqvz6c6qOM5mZ/rW7dkg9aagqiSNemgJ6BZFP8oseiwdzMB9VoLzwc9gE8GvCdi1zj6TZCS+6BX/7SB/Wf/xyuvRZ69SIEPPOM7/VDgh59mu0TkfKXy0rRLifZSs+Ox849t30POTqb5NxzY86raqV25jD/5D77wIsvwp13Qq9em68bCsFdd/kvSL6iM+iVqCJSWlTgIkOpcuhp1fV8vJH6q5+h9uXbCO3yLtx6K5xyStJpiOmmU5RDFyk/KnCRJ8mm+KWc/tfcDJMmEZowgdDGjTB+jN9sJY1iE+mmUzQFUaTrUkAvlCeegFGj4J//hBNPhIkT4atfTfvlWtEpIqkooOfb66/D6NHw17/CHnvAk0/C0UenfFnH1IlWdIpIKgro+fLf/8J118Ftt/mVnRMnEq65gPr/60btF5Lnv3v18p35jvlypVNEJBkF9KA5Bw88AJddBu+9B2edBTfeSHhVn6SDmrGDnhUVPlfe1qbphyKSPk1bDNLixfDtb8PPfga77grPPuuXh/bpk7JaUezx1lYf1DX9UEQyoR56EBobYfx4uOce6N0bpk+HM8/0UTki1aBmx+MXXAAvvwz77bcl+KuXLiLJKKDnYuNGv+Lnqqtg/XrCp0yifvcR1O7Zg1CHv31SDWrGHo/m0JubYd48/3uhe3ct5ReR5BTQU0i4UKeuDi66CJYtg6OOIjx0GoPO7ud72L+OH3xTDWpGj994o++pt7X555VLF5F0KIeeRHSg8sor/fdwGF9s4uST4cgj4dNPfbGJuXOpf6tf0hx5JqLpl2jGpqJCuXQRSU099CTaD2Q66q+oI7ToBL9Ef8IEuPTSzcUmglz40zH90tSkuecikpoCehI+SDtamh3Vbc3UPn0lnHIi/PrXsNtu7c5NliPPZn8VzTkXkUyVVUAPemOq0OeXUrf3VOoXf47ar64m9Pub4LvfTXx+nCAcO788aWELEZEclU1AD7S4w4cfwjXXwJ13EvrCFwjdeR2MmOAjcoY6zi/fqrCFiEhAchoUNbO3zGyJmb1sZp26L26qhTtpaW31ZYV23x3uuANGjIA33oDzzssqmMOW3HrU5sIW2bRPRCSJIGa5HO6c2y+dvXrzKefiDosWwUEH+SC+115+1eeUKe2KTWQjFIJJk7bUFgX/WDNWRCRoZZFyiebOJ03KYkbIv/4Fl18O998Pu+wCs2alLDaRqaamLY/NYNgwpVtEJHi5BnQHzDMzB0x1zk3reIKZjQBGAPTt2zfHt9ta1rnzSLEJJkzwKz7Hj4exY+Fznwu8jR2nNA4ZEvhbiIjkHNC/45xbY2ZfAuab2WvOuQWxJ0SC/DTwJehyfL+tZFUYOcdiE5nSXuYiUgg5BXTn3JrI97VmNgc4CFiQ/FXBymhBzxtv+GITTzzhi0387W9wzDEFaafmlYtIvmU9KGpm25rZ56OPge8BS4NqWCLhsN/rJBz2P0d7vxMmJEm3/Pe/Pp2yzz6wYIEvyvzqqwUL5iIihZBLD30nYI75wcMq4H+dc08G0qoEEuXLE/Z+ExSboE+ffDZTRKRTZB3QnXMrgX0DbEtKGeXLFy+GCy/00xEPPBDmzIGDDy5ga0VECqukdltMa655Y6OfS37ggX7Qc/p0XzkojWDeMZ0jIlJKSmoeetLZIps2bSk28cknfvDzqqtgu+3SunY60x+D3itGRCRIJRXQIUG+/OmnfXolUmyCyZP9as8MpErnBLpXjIhIHpRUymUrb7/ti00MGgTr1/s8+dy5GQdzSJ3OCWSvGBGRPCq5HjoAn30Gt9wCN920pdjEJZfANttkfclUi3+CLGAhIpIPpRXQnYM//tEH77ff9nuu3HILBLSlQLLFP1rtKSLFrnQC+rJlPk/+9NMwcKCPrEmKTeSDVnuKSDErjRz6ddfBvvvCSy/5fcpffLHgwVxEpNiVRg99wAAYPtznynfcsbNbIyJSlEojoJ9+uv8SEZGESiPlIiIiKZVUQNfSfBGRxEoj5YJWaoqIpFIyPfTYlZobNsDMmZ3dIhGR4lIyAb221i/LB7++6N57lXoREYlVMgE9FIJhw/xKf/CbK2o/FRGRLUomoAMMGQI9evieelUVvPOOeukiIlElFdCj+6kMH+7TLnff7QdKFdRFREosoIMP6n37+sFRbWUrIrJFyQV0SLMUnYhIF1My89BjaSv5BPX/AAAGPUlEQVRbEZGt5RzQzawSaADWOOe+n3uT0qOtbEVE2gsi5XIRsDyA64iISA5yCuhmtitwPHBPMM0REZFs5dpDnwRcBrQF0BYREclB1gHdzL4PrHXOLU5x3ggzazCzhsbGxmzfTkREUsilh/5t4Adm9hbwIHCEmd3f8STn3DTnXI1zrqZ37945vJ2IiCSTdUB3zo1zzu3qnOsHnAo87Zw7I7CWiYhIRgo6D33x4sX/NrO3s3z5jsC/g2xPQNSuzKhdmVG7MlOs7YLc2vaVdE4y51yW1y8sM2twztV0djs6Ursyo3ZlRu3KTLG2CwrTtpJc+i8iIltTQBcRKROlFNCndXYDElC7MqN2ZUbtykyxtgsK0LaSyaGLiEhypdRDFxGRJIoioJvZMWa2wsz+aWZj4xzvbmYPRY4/Z2b9Yo6Nizy/wsyOLnC7Ljazf5jZq2ZWZ2ZfiTnWamYvR74eL3C7zjKzxpj3Pyfm2Jlm9kbk68wCt+u2mDa9bmYfxRzLy/0ys+lmttbMliY4bmZ2e6TNr5rZN2OO5fNepWrXTyPtWWJmi8xs35hjb0Wef9nMGgrcrloz+zjm3+qqmGNJ//3z3K4xMW1aGvk87RA5ls/7tZuZPROJA8vM7KI45xTuM+ac69QvoBJ4ExgAVAOvAHt3OOc84HeRx6cCD0Ue7x05vzvQP3KdygK263CgZ+TxL6Ltivz8SSfer7OAO+K8dgdgZeT79pHH2xeqXR3OvwCYXoD7dRjwTWBpguPHAX8DDDgEeC7f9yrNdn0r+n7AsdF2RX5+C9ixk+5XLfCXXP/9g25Xh3NPwC90LMT92hn4ZuTx54HX4/z/WLDPWDH00A8C/umcW+mca8FvI3Bih3NOBO6LPH4UGGRmFnn+Qedcs3NuFfDPyPUK0i7n3DPOuU8jPz4L7BrQe+fUriSOBuY75/7jnPsQmA8c00ntOg2YFdB7J+ScWwD8J8kpJwIznfcs8EUz25n83quU7XLOLYq8LxTus5XO/Uokl89l0O0qyGcLwDn3nnPuxcjj/+K3Et+lw2kF+4wVQ0DfBXg35ufVbH1DNp/jnNsEfAz0SvO1+WxXrLPxv4WjepjflOxZM/thQG3KpF2DI3/ePWpmu2X42ny2i0hqqj/wdMzT+bpfqSRqdz7vVaY6frYcMM/MFpvZiE5oT8jMXjGzv5nZPpHniuJ+mVlPfFCcHfN0Qe6X+VTw/sBzHQ4V7DNWkiXoio2ZnQHUAN+Neforzrk1ZjYAeNrMljjn3ixQk/4MzHLONZvZufi/bo4o0Hun41TgUedca8xznXm/ipaZHY4P6N+Jefo7kXv1JWC+mb0W6cEWwov4f6tPzOw44E/A/xTovdNxAvB/zrnY3nze75eZfQ7/S2SUc25dkNfORDH00NcAu8X8vGvkubjnmFkVsB3QlOZr89kuzOxIYDzwA+dcc/R559yayPeVQD3+N3dB2uWca4ppyz3AAem+Np/tinEqHf4kzuP9SiVRu/N5r9JiZt/A//ud6Jxrij4fc6/WAnMILs2YknNunXPuk8jjvwLdzGxHiuB+RST7bOXlfplZN3wwf8A598c4pxTuM5aPgYIMBxWq8IMB/dkymLJPh3POp/2g6MORx/vQflB0JcENiqbTrv3xA0H/0+H57YHukcc7Am8Q0ABRmu3aOebxScCzbssgzKpI+7aPPN6hUO2KnLcnfpDKCnG/ItfsR+JBvuNpP2D1fL7vVZrt6osfE/pWh+e3BT4f83gRcEwB29Un+m+HD4zvRO5dWv/++WpX5Ph2+Dz7toW6X5H/9pnApCTnFOwzFtjNzvGmHIcfHX4TGB957lp8rxegB/BI5AP+PDAg5rXjI69bARxb4HY9BXwAvBz5ejzy/LeAJZEP9RLg7AK360ZgWeT9nwH2jHntsMh9/CcwtJDtivx8DXBTh9fl7X7he2vvARvxOcqzgZ8DP48cN+DOSJuXADUFulep2nUP8GHMZ6sh8vyAyH16JfJvPL7A7RoZ89l6lphfOPH+/QvVrsg5Z+EnScS+Lt/36zv4HP2rMf9Wx3XWZ0wrRUVEykQx5NBFRCQACugiImVCAV1EpEwooIuIlAkFdBGRMqGALiJSJhTQRUTKhAK6iEiZ+H+Fa46uBBRPGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#使用LinearRegression的随机数据回归\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "X= 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.rand(100,1)\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X,y)\n",
    "\n",
    "Xnew = np.array([[0],[2]])\n",
    "Xnewb = np.c_[np.ones((2,1)), Xnew]\n",
    "y_predict = reg.predict(Xnew)\n",
    "\n",
    "print(y_predict)\n",
    "plt.plot(Xnew,y_predict,\"r-\")\n",
    "plt.plot(X,y,\"b.\")\n",
    "#plt.axis([0,2,0,15])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）多元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考Scikit-learn手册中最小二乘线性回归的例程，并进行修改，实现对Diabetes dataset数据的多元线性回归。\n",
    "\n",
    "Data Set Characteristics:\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6530306ebf524389b4e30c67825475e51548099622854d2b8087669caf900a70)\n",
    "\n",
    "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times n_samples (i.e. the sum of squares of each column totals 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and extract data\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data\n",
    "diabetes_y = diabetes.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用评估回归拟合效果的指标：\n",
    "\n",
    "* 均方误差（Mean Squared Error）：测试数据集中所有样本点的预测误差的平方的均值；\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/834c6c5a2ab04333a3b26686c72b28dae3e9a3a1821640e3833894f091b82a62)\n",
    "\n",
    "* R方得分（R2 Score）：确定性相关系数，用于衡量\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fa58070fad8f4dd2bb8088ec04f9f5532e5c421ac5744888985ead72cc907d35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验与讨论\n",
    "* 选择特征数据中不同属性组合作为样本特征值，比较回归性能并分析原因（比较至少三组）。\n",
    "* 选择不同训练样本集和测试样本集的划分，比较回归性能（比较至少三组）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当比例约为10：1时，均方误差为1751.06，R方为0.9923\n",
      "当比例约为5：1时，均方误差为2666.92，R方为0.9945\n",
      "当比例约为50：1时，均方误差为1328.31，R方为0.9552\n"
     ]
    }
   ],
   "source": [
    "#考虑到第一题最好是使用较好的划分比例这样得出的结果会好一些，所以先做第二题\n",
    "#讨论第二题：不同划分比例得出的回归性能.三组数据全部使用所有特征值\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data\n",
    "diabetes_y = diabetes.target\n",
    "#划分比例1——test：train = 1：10\n",
    "Xtrain = diabetes_X[:-40]\n",
    "Xtest = diabetes_X[-40:]\n",
    "ytrain = diabetes_y[:-40]\n",
    "ytest = diabetes_y[-40:]\n",
    "reg1 = linear_model.LinearRegression()\n",
    "reg1.fit(Xtrain, ytrain)\n",
    "ans = reg1.predict(Xtest)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当比例约为10：1时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "#划分比例2——test：train = 1：5\n",
    "Xtrain = diabetes_X[:-80]\n",
    "Xtest = diabetes_X[-80:]\n",
    "ytrain = diabetes_y[:-80]\n",
    "ytest = diabetes_y[-80:]\n",
    "reg2 = linear_model.LinearRegression()\n",
    "reg2.fit(Xtrain, ytrain)\n",
    "ans = reg2.predict(Xtest)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当比例约为5：1时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "#划分比例3——test：train = 1：50\n",
    "Xtrain = diabetes_X[:-8]\n",
    "Xtest = diabetes_X[-8:]\n",
    "ytrain = diabetes_y[:-8]\n",
    "ytest = diabetes_y[-8:]\n",
    "reg3 = linear_model.LinearRegression()\n",
    "reg3.fit(Xtrain, ytrain)\n",
    "ans = reg3.predict(Xtest)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当比例约为50：1时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据实验二，我们以R方来衡量误差的话，会发现50：1的答案最佳，但由于比例差太多，害怕出现过拟合的问题，所以在实验一我取10：1进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当选取前三个特征值时，均方误差为3267.02，R方为0.9857\n",
      "当选取第4、5、6个特征值时，均方误差为3322.79，R方为0.9855\n",
      "当选取第7、8、9个特征值时，均方误差为3267.02，R方为0.9857\n"
     ]
    }
   ],
   "source": [
    "#实验一：取不同特征值比较其性能\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data\n",
    "diabetes_y = diabetes.target\n",
    "#划分比例1——test：train = 1：10\n",
    "Xtrain = diabetes_X[:-40]\n",
    "Xtest = diabetes_X[-40:]\n",
    "ytrain = diabetes_y[:-40]\n",
    "ytest = diabetes_y[-40:]\n",
    "Xtr = np.c_[Xtrain[:,0],Xtrain[:,1],Xtrain[:,2]]\n",
    "Xte = np.c_[Xtest[:,0],Xtest[:,1],Xtest[:,2]]\n",
    "reg1 = linear_model.LinearRegression()\n",
    "reg1.fit(Xtr, ytrain)\n",
    "ans = reg1.predict(Xte)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当选取前三个特征值时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "Xtr = np.c_[Xtrain[:,6],Xtrain[:,7],Xtrain[:,8]]\n",
    "Xte = np.c_[Xtest[:,6],Xtest[:,7],Xtest[:,8]]\n",
    "reg2 = linear_model.LinearRegression()\n",
    "reg2.fit(Xtr, ytrain)\n",
    "ans = reg2.predict(Xte)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当选取第4、5、6个特征值时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "Xtr = np.c_[Xtrain[:,0],Xtrain[:,1],Xtrain[:,2]]\n",
    "Xte = np.c_[Xtest[:,0],Xtest[:,1],Xtest[:,2]]\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(Xtr, ytrain)\n",
    "ans = reg.predict(Xte)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当选取第7、8、9个特征值时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 对数几率回归\n",
    "  对数几率回归模型为\n",
    "  \n",
    " $ln\\frac{y}{1-y} = \\boldsymbol w^T + b$ \n",
    "\n",
    "阅读Scikit-learn手册（https://scikit-learn.org/0.20/modules/linear_model.html#logistic-regression），熟悉LogisticRegression的用法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）两类数据分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制分类结果图形的函数\n",
    "\n",
    "def plot_classifier(classifier, X, y):\n",
    "    # define ranges to plot the figure \n",
    "    x_min, x_max = min(X[:, 0]) - 1.0, max(X[:, 0]) + 1.0\n",
    "    y_min, y_max = min(X[:, 1]) - 1.0, max(X[:, 1]) + 1.0\n",
    "\n",
    "    # denotes the step size that will be used in the mesh grid\n",
    "    step_size = 0.01\n",
    "\n",
    "    # define the mesh grid\n",
    "    x_values, y_values = np.meshgrid(np.arange(x_min, x_max, step_size), np.arange(y_min, y_max, step_size))\n",
    "\n",
    "    # compute the classifier output\n",
    "    mesh_output = classifier.predict(np.c_[x_values.ravel(), y_values.ravel()])\n",
    "\n",
    "    # reshape the array\n",
    "    mesh_output = mesh_output.reshape(x_values.shape)\n",
    "\n",
    "    # Plot the output using a colored plot \n",
    "    plt.figure()\n",
    "\n",
    "    # choose a color scheme you can find all the options \n",
    "    # here: http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    plt.pcolormesh(x_values, y_values, mesh_output, cmap=plt.cm.gray)\n",
    "\n",
    "    # Overlay the training points on the plot \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=80, edgecolors='black', linewidth=1, cmap=plt.cm.Paired)\n",
    "\n",
    "    # specify the boundaries of the figure\n",
    "    plt.xlim(x_values.min(), x_values.max())\n",
    "    plt.ylim(y_values.min(), y_values.max())\n",
    "\n",
    "    # specify the ticks on the X and Y axes\n",
    "    plt.xticks((np.arange(int(min(X[:, 0])-1), int(max(X[:, 0])+1), 1.0)))\n",
    "    plt.yticks((np.arange(int(min(X[:, 1])-1), int(max(X[:, 1])+1), 1.0)))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "X = np.array([[4, 7], [3.5, 8], [3.1, 6.2], [0.5, 1], [1, 2],[1.2, 1.9]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "# initialize the logistic regression classifier\n",
    "logregr = linear_model.LogisticRegression(solver='liblinear', C=100)\n",
    " # train the classifier\n",
    "logregr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " # draw datapoints and boundaries\n",
    "plot_classifier(logregr, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "def plot_classifier(classifier, X, y):\n",
    "    x_min, x_max = min(X[:, 0]) - 1.0, max(X[:, 0]) + 1.0\n",
    "    y_min, y_max = min(X[:, 1]) - 1.0, max(X[:, 1]) + 1.0\n",
    "\n",
    "    # denotes the step size that will be used in the mesh grid\n",
    "    step_size = 0.01\n",
    "\n",
    "    # define the mesh grid\n",
    "    x_values, y_values = np.meshgrid(np.arange(x_min, x_max, step_size), np.arange(y_min, y_max, step_size))\n",
    "    # compute the classifier output\n",
    "    mesh_output = classifier.predict(np.c_[x_values.ravel(), y_values.ravel()])\n",
    "    \n",
    "    # reshape the array\n",
    "    mesh_output = mesh_output.reshape(x_values.shape)\n",
    "    # Plot the output using a colored plot \n",
    "    plt.figure()\n",
    "\n",
    "    # choose a color scheme you can find all the options \n",
    "    # here: http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    plt.pcolormesh(x_values, y_values, mesh_output, cmap=plt.cm.gray)\n",
    "\n",
    "    # Overlay the training points on the plot \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=80, edgecolors='black', linewidth=1, cmap=plt.cm.Paired)\n",
    "\n",
    "    # specify the boundaries of the figure\n",
    "    plt.xlim(x_values.min(), x_values.max())\n",
    "    plt.ylim(y_values.min(), y_values.max())\n",
    "\n",
    "    # specify the ticks on the X and Y axes\n",
    "    plt.xticks((np.arange(int(min(X[:, 0])-1), int(max(X[:, 0])+1), 1.0)))\n",
    "    plt.yticks((np.arange(int(min(X[:, 1])-1), int(max(X[:, 1])+1), 1.0)))\n",
    "\n",
    "    plt.show()\n",
    "X = np.array([[4, 7], [3.5, 8], [3.1, 6.2], [0.5, 1], [1, 2],[1.2, 1.9]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "logregr = linear_model.LogisticRegression(solver='liblinear', C=100)\n",
    "logregr.fit(X, y)\n",
    "plot_classifier(logregr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）多类数据分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn中的LogisticRegression可以实现\"一对多\"分类或Softmax回归的多类分类。以鸢尾花数据为例，应用LogisticRegression进行多类分类。\n",
    "\n",
    "Data Set Characteristics:\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e75773b7c55d497b96df7443f5033735936a5f4dcd244dacb4e791590ecd65f8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,1:3]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregr = linear_model.LogisticRegression(solver='liblinear', C=100)\n",
    " # train the classifier\n",
    "logregr.fit(X, y)\n",
    "logregr.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验与讨论\n",
    "* 以平均精度（LogisticRegression.score(X,y)）为指标，比较不同特征组合与数据集划分的分类性能（至少三组）。\n",
    "* 了解其它分类性能度量指标实现方法（选做）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当划分比例为1：10时，得分为1.00\n",
      "当划分比例为1：20时，得分为1.00\n",
      "当划分比例为1：5时，得分为0.87\n",
      "当取第1、2个特征时，得分为0.73\n",
      "当取第1、3个特征时，得分为1.00\n",
      "当取第3、4个特征时，得分为1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "#先选取不同的划分比例，先取1：10\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.1)\n",
    "logregr1 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr1.fit(xtrain, ytrain)\n",
    "ans = logregr1.score(xtest, ytest)\n",
    "print('当划分比例为1：10时，得分为{:.2f}'.format(ans))\n",
    "#取1：20\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.05)\n",
    "logregr2 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr2.fit(xtrain, ytrain)\n",
    "ans = logregr2.score(xtest, ytest)\n",
    "print('当划分比例为1：20时，得分为{:.2f}'.format(ans))\n",
    "#取1:5\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2)\n",
    "logregr3 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr3.fit(xtrain, ytrain)\n",
    "ans = logregr3.score(xtest, ytest)\n",
    "print('当划分比例为1：5时，得分为{:.2f}'.format(ans))\n",
    "\n",
    "#结果取1：5与1：20时效果都不错，下面选取不同特征值，选取比例为1：5\n",
    "#先选取第1、2个的特征值\n",
    "X1 = X[:,0:1]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X1, y, test_size = 0.2)\n",
    "logregr4 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr4.fit(xtrain, ytrain)\n",
    "ans = logregr4.score(xtest, ytest)\n",
    "print('当取第1、2个特征时，得分为{:.2f}'.format(ans))\n",
    "#再选取第1、3个的特征值\n",
    "X2 = np.c_[X[:,0],X[:,2]]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X2, y, test_size = 0.2)\n",
    "logregr5 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr5.fit(xtrain, ytrain)\n",
    "ans = logregr5.score(xtest, ytest)\n",
    "print('当取第1、3个特征时，得分为{:.2f}'.format(ans))\n",
    "#最后选取第3、4个的特征值\n",
    "X2 = X[:,2:3]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X2, y, test_size = 0.2)\n",
    "logregr6 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr6.fit(xtrain, ytrain)\n",
    "ans = logregr6.score(xtest, ytest)\n",
    "print('当取第3、4个特征时，得分为{:.2f}'.format(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、实验结果与分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（请给出实验内容中“实验与讨论”中的结果及其分析。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当比例约为10：1时，均方误差为1751.06，R方为0.9923\n",
      "当比例约为5：1时，均方误差为2666.92，R方为0.9945\n",
      "当比例约为50：1时，均方误差为1328.31，R方为0.9552\n",
      "当选取前三个特征值时，均方误差为3267.02，R方为0.9857\n",
      "当选取第4、5、6个特征值时，均方误差为3322.79，R方为0.9855\n",
      "当选取第7、8、9个特征值时，均方误差为3267.02，R方为0.9857\n"
     ]
    }
   ],
   "source": [
    "#考虑到第一题最好是使用较好的划分比例这样得出的结果会好一些，所以先做第二题\n",
    "#讨论第二题：不同划分比例得出的回归性能.三组数据全部使用所有特征值\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data\n",
    "diabetes_y = diabetes.target\n",
    "#划分比例1——test：train = 1：10\n",
    "Xtrain = diabetes_X[:-40]\n",
    "Xtest = diabetes_X[-40:]\n",
    "ytrain = diabetes_y[:-40]\n",
    "ytest = diabetes_y[-40:]\n",
    "reg1 = linear_model.LinearRegression()\n",
    "reg1.fit(Xtrain, ytrain)\n",
    "ans = reg1.predict(Xtest)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当比例约为10：1时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "#划分比例2——test：train = 1：5\n",
    "Xtrain = diabetes_X[:-80]\n",
    "Xtest = diabetes_X[-80:]\n",
    "ytrain = diabetes_y[:-80]\n",
    "ytest = diabetes_y[-80:]\n",
    "reg2 = linear_model.LinearRegression()\n",
    "reg2.fit(Xtrain, ytrain)\n",
    "ans = reg2.predict(Xtest)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当比例约为5：1时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "#划分比例3——test：train = 1：50\n",
    "Xtrain = diabetes_X[:-8]\n",
    "Xtest = diabetes_X[-8:]\n",
    "ytrain = diabetes_y[:-8]\n",
    "ytest = diabetes_y[-8:]\n",
    "reg3 = linear_model.LinearRegression()\n",
    "reg3.fit(Xtrain, ytrain)\n",
    "ans = reg3.predict(Xtest)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当比例约为50：1时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "\n",
    "#实验一：取不同特征值比较其性能\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data\n",
    "diabetes_y = diabetes.target\n",
    "#划分比例1——test：train = 1：10\n",
    "Xtrain = diabetes_X[:-40]\n",
    "Xtest = diabetes_X[-40:]\n",
    "ytrain = diabetes_y[:-40]\n",
    "ytest = diabetes_y[-40:]\n",
    "Xtr = np.c_[Xtrain[:,0],Xtrain[:,1],Xtrain[:,2]]\n",
    "Xte = np.c_[Xtest[:,0],Xtest[:,1],Xtest[:,2]]\n",
    "reg1 = linear_model.LinearRegression()\n",
    "reg1.fit(Xtr, ytrain)\n",
    "ans = reg1.predict(Xte)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当选取前三个特征值时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "Xtr = np.c_[Xtrain[:,6],Xtrain[:,7],Xtrain[:,8]]\n",
    "Xte = np.c_[Xtest[:,6],Xtest[:,7],Xtest[:,8]]\n",
    "reg2 = linear_model.LinearRegression()\n",
    "reg2.fit(Xtr, ytrain)\n",
    "ans = reg2.predict(Xte)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当选取第4、5、6个特征值时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))\n",
    "Xtr = np.c_[Xtrain[:,0],Xtrain[:,1],Xtrain[:,2]]\n",
    "Xte = np.c_[Xtest[:,0],Xtest[:,1],Xtest[:,2]]\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(Xtr, ytrain)\n",
    "ans = reg.predict(Xte)\n",
    "mse = 0\n",
    "summ = 0\n",
    "lenth = len(ans)\n",
    "for i in range(lenth):\n",
    "    summ+=(ans[i]-ytest[i])*(ans[i]-ytest[i])\n",
    "mse = summ/lenth\n",
    "yave = 0\n",
    "for i in ytest:\n",
    "    yave += i \n",
    "yave/=lenth\n",
    "sumr = 0\n",
    "for i in range(lenth): \n",
    "    sumr+=(ytest[i]-yave)*(ytest[i]-yave)\n",
    "r = summ/sumr/lenth\n",
    "print('当选取第7、8、9个特征值时，均方误差为{:.2f}，R方为{:.4f}'.format(mse, 1-r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验一：\n",
    "  当比例约为10：1时，均方误差为1751.06，R方为0.9923\n",
    "  当比例约为5：1时，均方误差为2666.92，R方为0.9945\n",
    "  当比例约为50：1时，均方误差为1328.31，R方为0.9552\n",
    "  当选取前三个特征值时，均方误差为3267.02，R方为0.9857\n",
    "  当选取第4、5、6个特征值时，均方误差为3322.79，R方为0.9855\n",
    "  当选取第7、8、9个特征值时，均方误差为3267.02，R方为0.9857\n",
    "  \n",
    "  根据讨论二结果，我们会发现当取样train：test比例接近10：1时结果最佳\n",
    "  \n",
    "  根据对讨论一的观察，我们会发现性别、年龄与后面的体测指标其实误差接近，但都小于10个特征值一起使用的情况（及欠拟合）。这说明每个特征值都对结果产生了影响。\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当划分比例为1：10时，得分为0.87\n",
      "当划分比例为1：20时，得分为1.00\n",
      "当划分比例为1：5时，得分为1.00\n",
      "当取第1、2个特征时，得分为0.67\n",
      "当取第1、3个特征时，得分为0.93\n",
      "当取第3、4个特征时，得分为0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "#先选取不同的划分比例，先取1：10\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.1)\n",
    "logregr1 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr1.fit(xtrain, ytrain)\n",
    "ans = logregr1.score(xtest, ytest)\n",
    "print('当划分比例为1：10时，得分为{:.2f}'.format(ans))\n",
    "#取1：20\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.05)\n",
    "logregr2 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr2.fit(xtrain, ytrain)\n",
    "ans = logregr2.score(xtest, ytest)\n",
    "print('当划分比例为1：20时，得分为{:.2f}'.format(ans))\n",
    "#取1:5\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2)\n",
    "logregr3 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr3.fit(xtrain, ytrain)\n",
    "ans = logregr3.score(xtest, ytest)\n",
    "print('当划分比例为1：5时，得分为{:.2f}'.format(ans))\n",
    "\n",
    "#结果取1：5与1：20时效果都不错，下面选取不同特征值，选取比例为1：5\n",
    "#先选取第1、2个的特征值\n",
    "X1 = X[:,0:1]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X1, y, test_size = 0.2)\n",
    "logregr4 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr4.fit(xtrain, ytrain)\n",
    "ans = logregr4.score(xtest, ytest)\n",
    "print('当取第1、2个特征时，得分为{:.2f}'.format(ans))\n",
    "#再选取第1、3个的特征值\n",
    "X2 = np.c_[X[:,0],X[:,2]]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X2, y, test_size = 0.2)\n",
    "logregr5 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr5.fit(xtrain, ytrain)\n",
    "ans = logregr5.score(xtest, ytest)\n",
    "print('当取第1、3个特征时，得分为{:.2f}'.format(ans))\n",
    "#最后选取第3、4个的特征值\n",
    "X2 = X[:,2:3]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X2, y, test_size = 0.2)\n",
    "logregr6 = linear_model.LogisticRegression(solver='liblinear', C=90)\n",
    "logregr6.fit(xtrain, ytrain)\n",
    "ans = logregr6.score(xtest, ytest)\n",
    "print('当取第3、4个特征时，得分为{:.2f}'.format(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析：\n",
    "\t当划分比例为1:10 1:5 1:20时效果都很好。于是选择1：5的划分比例\n",
    " \t\n",
    "    取特征值时，对于1、3 和3、4个特征值拟合效果比较好，但1、2个特征值拟合效果极差。所以可以推断，第二个特征值其实对该样本的结果相关性很低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
